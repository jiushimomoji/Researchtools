{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#机器学习与神经网络研究计划\" data-toc-modified-id=\"机器学习与神经网络研究计划-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>机器学习与神经网络研究计划</a></span><ul class=\"toc-item\"><li><span><a href=\"#研究背景\" data-toc-modified-id=\"研究背景-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>研究背景</a></span><ul class=\"toc-item\"><li><span><a href=\"#AI(Artificial-Intelligence)-and-DeepLearning\" data-toc-modified-id=\"AI(Artificial-Intelligence)-and-DeepLearning-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>AI(Artificial Intelligence) and DeepLearning</a></span></li><li><span><a href=\"#及其应用\" data-toc-modified-id=\"及其应用-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>及其应用</a></span></li></ul></li><li><span><a href=\"#硬件：CPU和GPU--Nvidia\" data-toc-modified-id=\"硬件：CPU和GPU--Nvidia-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>硬件：CPU和GPU--Nvidia</a></span></li><li><span><a href=\"#软件：编程语言和神经网络架构\" data-toc-modified-id=\"软件：编程语言和神经网络架构-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>软件：编程语言和神经网络架构</a></span></li><li><span><a href=\"#机器学习算法举例\" data-toc-modified-id=\"机器学习算法举例-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>机器学习算法举例</a></span></li><li><span><a href=\"#神经网络（Neural-network）\" data-toc-modified-id=\"神经网络（Neural-network）-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>神经网络（Neural network）</a></span><ul class=\"toc-item\"><li><span><a href=\"#卷积神经网络（CNN）\" data-toc-modified-id=\"卷积神经网络（CNN）-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>卷积神经网络（CNN）</a></span></li><li><span><a href=\"#LeNet\" data-toc-modified-id=\"LeNet-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>LeNet</a></span></li><li><span><a href=\"#GoogLeNet\" data-toc-modified-id=\"GoogLeNet-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>GoogLeNet</a></span></li><li><span><a href=\"#CNN的结构\" data-toc-modified-id=\"CNN的结构-1.5.4\"><span class=\"toc-item-num\">1.5.4&nbsp;&nbsp;</span>CNN的结构</a></span></li></ul></li><li><span><a href=\"#卷积神经网络CNN的核心——卷积\" data-toc-modified-id=\"卷积神经网络CNN的核心——卷积-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>卷积神经网络CNN的核心——卷积</a></span><ul class=\"toc-item\"><li><span><a href=\"#一维卷积\" data-toc-modified-id=\"一维卷积-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>一维卷积</a></span></li><li><span><a href=\"#二维卷积：full、-same、-valid\" data-toc-modified-id=\"二维卷积：full、-same、-valid-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>二维卷积：full、 same、 valid</a></span></li></ul></li><li><span><a href=\"#数学基础\" data-toc-modified-id=\"数学基础-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>数学基础</a></span></li><li><span><a href=\"#算法难点与学习重点\" data-toc-modified-id=\"算法难点与学习重点-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>算法难点与学习重点</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习与神经网络研究计划\n",
    "\n",
    "## 研究背景\n",
    "![u=1217736711,833465301&fm=27&gp=0.jpg](OneApplicationOfPix2pix/u=1217736711,833465301&fm=27&gp=0.jpg)\n",
    "自从2016年谷歌围棋人工智能AlphaGo战胜李世石，AI概念就红得发紫，国际上的网络公司Google、Facebook、Amazon早已纷纷把研发重心放在了机器学习与神经网络上，国内的阿里、腾讯、百度紧跟其后。如今不论是送外卖，搞团购，卖车，或是推荐莆田医院的，是个公司都会标榜自己是搞人工智能的。人工智能的产品已经深入到人们生活的方方面面，譬如淘宝的推荐、今日头条、和手机的语音识别、输入法等。这些应用涵盖，计算机视觉、模式识别、数据挖掘、统计学习和自然语言处理等领域。AI、机器学习与神经网络如此大红大紫，然而它们到底是什么呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI(Artificial Intelligence) and DeepLearning\n",
    "[人工智能、机器学习和深度学习之间的区别和联系](https://www.leiphone.com/news/201609/gox8CoyqMrXMi4L4.html)\n",
    "![57ce9265aae3f.png](OneApplicationOfPix2pix/57ce9265aae3f.png)\n",
    "- 人工智能（Artificial Intelligence）——为机器赋予人的智能\n",
    "- 机器学习——实现人工智能的一种方法\n",
    "- 深度学习——实现机器学习的一种技术\n",
    "- 神经网络——实现深度学习的一种算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 及其应用\n",
    "机器学习在一定程度上可分为：监督学习、强化学习和非监督学习。针对不同的任务应选取不同的机器学习方法。\n",
    "![2018-03-07 15-23-03屏幕截图.png](OneApplicationOfPix2pix/ml.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 硬件：CPU和GPU--Nvidia\n",
    "- [哪些GPU更适合深度学习和数据库？](http://www.infoq.com/cn/articles/which-gpu-to-get-for-deep-learning?utm_source=articles_about_AI&utm_medium=link&utm_campaign=AI)\n",
    "\n",
    "人工智能的春天已经到来，其重要因素之一是 GPU 的处理能力，能让神经网络的智能可以随数据增加而继续提升，突破了过去的人工智能所能达到的平台，训练饱和极限（智力容量）大大上移。很早以前神经网络的算法就已经被提出了，然而起初它并没有获得太多的关注，原因是当时没有能够支持其算法的硬件，相比传统的CPU，GPU更适合用于训练神经网络模型。我们都知道深度学习可能会用到比较大的数据，而CPU是很难带动大数据的训练的，GPU就不一样了，它会让训练的速度提升很多，所以，我们往往愿意选择GPU来训练模型。\n",
    "\n",
    "- 综合最好的GPU: Titan X Pascal和GTX 1080 Ti\n",
    "- 划算，较贵：GTX 1080 Ti, GTX 1070\n",
    "- 划算，较便宜: GTX 1060\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 软件：编程语言和神经网络架构\n",
    "\n",
    "![QQ截图20170215140736.png](OneApplicationOfPix2pix/QQ截图20170215140736.png)\n",
    "\n",
    "说到学习编程就不得不提到python，其实包括c++、Java、lua、MATLAB、Julia、R、Perl、python、Ruby在内的多种语言都能搞机器学习，那为什么只有python独占鳌头，被推向了机器学习第一语言的神坛呢？这是由于在神经网络的发展过程中，科学家和工程师喜欢用python快速实现模型，python的面相对象和丰富的工具包，使其能够方便的构造神经网络模型，同时又易读易维护。就算不搞机器学习，如果要学编程，那python也是个极佳选择，因为python在机器学习、数据分析、爬虫、Web 网站、游戏、后台服务、运维等方面都能胜任，因为什么事情都能掺和上一脚的特性，python被称为“万能胶水”。\n",
    "\n",
    "如果选择机器学习工具，综合考虑下首选：\n",
    "- 选择 Python\n",
    "- GPU 支持\n",
    "\n",
    "\n",
    "主要框架：用于机器智能的开源软件库--Application Programming Interface(API:应用程序编程接口)\n",
    "- PyTorch (Facebook 的人工智能研究所用的框架)更适合于在研究中快速进行原型设计、业余爱好者和小型项目\n",
    "- TensorFlow(Google 的人工智能研究所用的框架)则更适合大规模的调度，尤其当考虑到跨平台和嵌入式调度操作时\n",
    "- Keras:是一个更高级的API，可配置后端，支持TensorFlow、Theano和CNTK，也许在不久的将来也会支持PyTorch。Keras就像TensorFlow里的tf.contrib库一样。\n",
    "\n",
    "重点介绍Tensorflow这个框架，Tensorflow背靠Google大树，是目前最火的框架，如果你想做一名AI工程师，那学Tensorflow一定是最好的选择。PyTorch也是一个不错的框架。而Keras是基于Tensorflow又进行一层封装，当然也有基于Theano版本的，因为高度封装，使用起来异常简单，简单到什么程度呢？你只需要十来行代码就能搞出来一个简单神经网络模型，但与此对应的是灵活度并不高。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习算法举例\n",
    "机器学习算法有很多，早期的经典算法有，回归算法、正则化算法、聚类算法等，而神经网络方法尤其是深度神经网络由于其强大的功能和使用范围而受到广泛的关注。\n",
    "[机器学习算法汇总：人工神经网络、深度学习及其它](https://www.csdn.net/article/2014-06-27/2820429)\n",
    "- 回归算法\n",
    "- 基于实例的算法\n",
    "- 正则化方法\n",
    "- 决策树学习\n",
    "- 贝叶斯方法\n",
    "- 聚类算法\n",
    "- 神经网络\n",
    "![53ad11ad37c58.jpg.png](OneApplicationOfPix2pix/53ad11ad37c58.jpg.png)\n",
    "- 深度神经网络\n",
    "![53ad11cbc336e.jpg](OneApplicationOfPix2pix/53ad11cbc336e.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络（Neural network）\n",
    "[一文看懂25个神经网络模型 ](http://blog.csdn.net/scutjy2015/article/details/74170794)\n",
    "![288d000065e119541754.jpeg](OneApplicationOfPix2pix/288d000065e119541754.jpeg)\n",
    "神经网络有很多种模型，针对不同的问题，应选的不同的神经网络。这里详细介绍针对图像识别的卷积神经网络（CNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络（CNN） \n",
    "\n",
    "[CNN的发展史](https://www.cnblogs.com/52machinelearning/p/5821591.html)\n",
    "![288a000233e0418a6c10.jpeg](OneApplicationOfPix2pix/288a000233e0418a6c10.jpeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Deep Learning回顾：LeNet-1986、AlexNet-2012、GoogLeNet-2014、VGG-2014、ResNet\n",
    "\n",
    "![imagenethistory.png](OneApplicationOfPix2pix/imagenethistory.png)\n",
    "随着硬件计算能力和存储容量的提高，以及能够支持的深度神经网络层数的增加，深度神经网络的代表之一卷积神经网络对于图像的识别能力已经超越了人眼。在同样的ImageNet数据集合上，人眼的辨识错误率大概在5.1%，也就是目前的Deep Learning模型的识别能力已经超过了人眼。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet\n",
    "![lenet.png](OneApplicationOfPix2pix/lenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogLeNet\n",
    "![googlenet.png](OneApplicationOfPix2pix/googlenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN的结构\n",
    "以上展示的不同卷积神经网络，除了细节结构的不同，主要区别在于网络的层数。 最初用于识别手写体邮政编码的LeNet只有6层，上图的GoogLeNet为22层，而152层的ResNet对图像的识别能力已经超越了人眼。动辄上百层的深度卷积神经网络，看似很复杂，其实分工明确。其各个层的主要功能如下：\n",
    "-    输入层：用于数据的输入\n",
    "-    卷积层：使用卷积核进行特征提取和特征映射\n",
    "-    激励层：由于卷积也是一种线性运算，因此需要增加非线性映射\n",
    "-    池化层：进行下采样，对特征图稀疏处理，减少数据运算量。\n",
    "-    全连接层：通常在CNN的尾部进行重新拟合，减少特征信息的损失\n",
    "-    输出层：用于输出结果\n",
    "\n",
    "当然中间还可以使用一些其他的功能层:\n",
    "\n",
    "-    归一化层（Batch Normalization）：在CNN中对特征的归一化\n",
    "-    切分层：对某些（图片）数据的进行分区域的单独学习\n",
    "-    融合层：对独立进行特征学习的分支进行融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络CNN的核心——卷积\n",
    "卷积神经网络（Convolutional Neural Network,CNN）各个不同层之间的对图像的特征的提取，主要是通过卷积实现的。卷积是个数学概念，这里直接反应了，数学基础在神经网络中的重要基础地位。\n",
    "###  一维卷积\n",
    "![20161021122536421.png](OneApplicationOfPix2pix/20161021122536421.png)\n",
    "\n",
    "\n",
    "![20161021122942255.gif](OneApplicationOfPix2pix/20161021122942255.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维卷积：full、 same、 valid \n",
    "<div style=\"float:left; width:800px;\">\n",
    "<span style=\"float:left; width:400px;\"><img src =\"OneApplicationOfPix2pix/20161021141659634.gif\"></span>\n",
    "<span style=\"float:left; width:400px;\"><img src =\"OneApplicationOfPix2pix/20161021135241205.gif\"></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学基础\n",
    "[关于机器学习，我总结了可能是目前最全面最无痛的入门路径和资源！](http://mp.weixin.qq.com/s/7Dt5IJmTVM0srmZgSn8J3A)\n",
    "理解并实现深度神经网络看似是个编程问题，实际上是数学问题，这一点对于主攻算法的工程师尤其重要。所以必备的数学基础是不可缺少的。这里将涉及到的主要数学概念列出如下。\n",
    "\n",
    "一. 高等数学：\n",
    "\n",
    "1. 导数及偏导数，对应机器学习中的梯度，机器学习中学习的参数需要通过梯度下降进行更新；\n",
    "2. 复合函数的链式法则，同1一样，目的也是为了求出梯度更新参数，但因为深度学习网络有多层，所以模型的预测函数是个复合函数，我们需要通过链式法则从后往前求出每层参数的梯度，进而更新每层里的参数，这也就是大名鼎鼎的“反向传播法”；\n",
    "3. 同时可以去了解下数学中的最优化问题，大概就是目标函数在什么条件下能够取到最值的问题，因为机器学习的问题到最后都是要转化为一个损失函数最优化的问题。\n",
    "\n",
    "二. 线性代数：\n",
    "\n",
    "1. 标量、向量、矩阵及张量的定义及运算，让我们再回顾下，在机器的眼里，所有的数据都可为矩阵，机器学习的过程其实也就是矩阵计算的过程。这也就是NVIDIA的GPU在近两年那么火的原因，因为GPU在矩阵计算上天然有很大的优势。\n",
    "2. 范数，对应机器学习中正则项，正则项通常会加在已有的损失函数上用来减少训练的过拟合问题；\n",
    "3. 常见的距离计算方式：欧式距离、曼哈顿距离、余弦距离等，我们之前说过数据样本可以表示为其特征空间里的点，而距离可以用来衡量他们的相似度；\n",
    "\n",
    "三.概率论：\n",
    "\n",
    "1. 条件概率、贝叶斯，基于概率论的分类方法经常会用到；\n",
    "2. 期望与方差，机器学习里一般都会对数据进行normalized的处理，这个时候很可能会用到期望和方差；\n",
    "3. 协方差，能够表征两个变量的相关性，在PCA降维算法中有用到，变量越相关，我们越可能对他们进行降维处理；\n",
    "4. 常见分布：0-1分布、二项分布、高斯分布等，高斯分布很重要，数据normalized跟它有关，参数的初始化特跟它有关；\n",
    "5. 最大似然估计，在推导逻辑回归的损失函数时会用到；\n",
    "\n",
    "四. 信息论：\n",
    "\n",
    "1. 需要去了解下交叉熵的概念\n",
    "2. 分类问题的损失函数等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法难点与学习重点\n",
    "\n",
    "![ailc](OneApplicationOfPix2pix/ailc.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入门容易深入难，这条曲线同时也能描述AI人才的收入水平。工具和框架本身的发展，让设计模型所需的代码写得越来越简洁。10年前从头用C++和矩阵库实现梯度下降还是有不小的门槛的，动辄上千行代码。而当今几十行Keras甚至图形化的模型构建工具，让小学生都能设计出可用的二分类模型。不仅如此，深度学习本身的性质，造成了明显的数学鸿沟。由于模型存在大量的非线性和复杂的层次关系，且输入信号（例如图像，文本）也很复杂，因此严格的数学论证是需要极高的抽象技巧的。只有凤毛棱角的专家，能深入到模型最深处，用数值分析和理论证明给出严谨的答案。\n",
    "\n",
    "面向大众AI科普节目，最常讨论的便是“AI时代如何不被机器所取代”。最容易且最快被取代的反而是算法工程师。算法岗比工程岗更容易被取代。 在现有技术下，由于业务需求的复杂性， 自动生成一套软件App或服务几乎不可能的（否则就已经进入强人工智能时代了），但模型太容易被形式化地定义了。根据数据性质，自动生成各个领域的端到端（end2end）的模型也逐渐在工业上可用了：图像语音和广告推荐的飞速发展，直接套用即可。理论和经验越来越完善，人变得越来越可替代。特征可以自动生成和优选，特征工程师失业了； 深度网络采用经典结构即能满足一般业务需求，参数搜索在AutoML下变得越来越方便，调参工程师的饭碗也丢了； 以前需要大力气搭建的数据回流和预测的链路，已经成了公司的基础组件，数据工程师也没事干了。  此处引用老板经常说的一句话：机器都能干了，要你干吗？\n",
    "\n",
    "人工智能已经火了至少五年，它在未来五年是否火爆我们不能确定，但一定会更加两极化：偏基础的功能一般程序员就能搞定，像白开水一样普通。而针对更复杂模型甚至强人工智能的研究会成为少数人的专利。作为专业博士培养，首先是深入原理和底层，类似TensorFlow的核心代码要看懂记熟，要有严格的理论基础，特别是相关的数学理论。不能被工具带来的易用性迷惑双眼。要熟悉工具箱里每种函数的品性，对流动在模型里的数据有足够的嗅觉，在调参初期就能对不靠谱的参数快速剪枝。\n",
    "\n",
    "做算法需要扎实的数学理论和缜密的思维。有时候一行代码和一个参数的修改，背后是艰辛的思考和实验，再一次强调做算法太需要严谨和缜密的思维了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以学习重点应放在以下几个方面：\n",
    "1. 扎实数学基础\n",
    "- 掌握并熟练主要的神经网络编程语言和开发框架\n",
    "- 研读相关的著作 譬如，Ian Goodfellow等人合著的《Deep Learning》\n",
    "- 紧跟相关的论文\n",
    "- 确定自己的研究方向，在实践中加深理解。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    ""
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "Chinese Sim",
   "targetLang": "",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
